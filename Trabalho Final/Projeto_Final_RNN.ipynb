{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Alunos:\n",
        "*   Fabio Cardoso - fc2@cesar.school\n",
        "*   Andréa Fonseca - asf4@cesar.school"
      ],
      "metadata": {
        "id": "FUBDcWlpLbca"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dataset\n",
        "https://www.kaggle.com/datasets/juniorbueno/neural-networks-homer-and-bart-classification"
      ],
      "metadata": {
        "id": "ox3qfIuTLqJe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importação das bibliotecas"
      ],
      "metadata": {
        "id": "pKd79DNWLzD8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "t9HyceKhoTv6"
      },
      "outputs": [],
      "source": [
        "from os.path import exists\n",
        "import torch\n",
        "import zipfile"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.optim.lr_scheduler import StepLR"
      ],
      "metadata": {
        "id": "qv76fPiQohIC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Importando o dataset"
      ],
      "metadata": {
        "id": "PEMDAiTyL1lb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tECer0ubGVzT",
        "outputId": "fefbd23c-0d1a-4979-a2bc-029266540f2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/gdrive/My Drive/Bart_Homer.zip'\n",
        "zip_object = zipfile.ZipFile(file = path, mode = 'r')\n",
        "zip_object.extractall('./')\n",
        "zip_object.close()"
      ],
      "metadata": {
        "id": "6xOo1W88GgXK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "5e21dd30-d0f1-4dce-f073-56888f3c7051"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'https://drive.google.com/file/d/1b1b1Zay2_TiNd2XvEdKOjaucQgLVryjb/view?usp=drive_link'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-e08020b83f1b>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://drive.google.com/file/d/1b1b1Zay2_TiNd2XvEdKOjaucQgLVryjb/view?usp=drive_link'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mzip_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mzip_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mzip_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[1;32m   1249\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'https://drive.google.com/file/d/1b1b1Zay2_TiNd2XvEdKOjaucQgLVryjb/view?usp=drive_link'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir_train = '/content/Bart_Homer/Treinamento'\n",
        "data_dir_test = '/content/Bart_Homer/Teste'"
      ],
      "metadata": {
        "id": "mrXC1IXhovly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Definição da Rede Neural"
      ],
      "metadata": {
        "id": "j6AzcyX3MSFf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NetBartHomer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NetBartHomer, self).__init__()\n",
        "        self.dense = nn.Sequential(\n",
        "            nn.Linear(224 * 224 * 3, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = x.view(-1, 224 * 224 * 3) # Reshape to match the expected input size\n",
        "      x = self.dense(x)\n",
        "      output = F.log_softmax(x, dim=1)\n",
        "      return output\n",
        "\n",
        "model = NetBartHomer()"
      ],
      "metadata": {
        "id": "vzU1r6U8ok2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Função para treinamento do modelo"
      ],
      "metadata": {
        "id": "IirC60iHMY1t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(log_interval, dry_run, model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target[:output.size(0)])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "            if dry_run:\n",
        "                break"
      ],
      "metadata": {
        "id": "ckx-D8y6onR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Função para o teste do modelo"
      ],
      "metadata": {
        "id": "0pdFQ1K-Mf3o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "metadata": {
        "id": "EI5K0Oj_op5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Função do modelo e avaliação"
      ],
      "metadata": {
        "id": "P2dPW8EDMoP3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "\n",
        "torch.manual_seed(14)\n",
        "\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "train_kwargs = {'batch_size': 5}\n",
        "test_kwargs = {'batch_size': 25}\n",
        "if use_cuda:\n",
        "    cuda_kwargs = {'num_workers': 1,\n",
        "                    'pin_memory': True,\n",
        "                    'shuffle': True}\n",
        "    train_kwargs.update(cuda_kwargs)\n",
        "    test_kwargs.update(cuda_kwargs)\n",
        "\n",
        "transform_train=transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomAffine(degrees=7, translate=(0, 0.07), shear=0.2, scale=(1, 1.2)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "    ])\n",
        "\n",
        "transform_test = transforms.Compose(\n",
        "    [\n",
        "     transforms.Resize([224,224]),\n",
        "     transforms.ToTensor()\n",
        "    ]\n",
        ")\n",
        "\n",
        "dataset1 = train_dataset = datasets.ImageFolder(data_dir_train, transform=transform_train)\n",
        "dataset2 = test_dataset = datasets.ImageFolder(data_dir_test, transform=transform_test)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset1,**train_kwargs)\n",
        "test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)\n",
        "\n",
        "model = NetBartHomer().to(device)\n",
        "optimizer = optim.Adadelta(model.parameters(), lr=0.1)\n",
        "\n",
        "epochs = 20\n",
        "scheduler = StepLR(optimizer, step_size=1, gamma=0.7)\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    train(10, False, model, device, train_loader, optimizer, epoch)\n",
        "    test(model, device, test_loader)\n",
        "    scheduler.step()\n",
        "\n",
        "torch.save(model.state_dict(), \"homer_bart.pt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXNOJzT4pxlE",
        "outputId": "8a47e8d8-b4b9-4b1a-d631-847a5d06b1e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/202 (0%)]\tLoss: 0.697115\n",
            "Train Epoch: 1 [50/202 (24%)]\tLoss: 0.024825\n",
            "Train Epoch: 1 [100/202 (49%)]\tLoss: 1.891869\n",
            "Train Epoch: 1 [150/202 (73%)]\tLoss: 1.543227\n",
            "Train Epoch: 1 [80/202 (98%)]\tLoss: 1.522758\n",
            "\n",
            "Test set: Average loss: 0.8405, Accuracy: 40/67 (60%)\n",
            "\n",
            "Train Epoch: 2 [0/202 (0%)]\tLoss: 1.723411\n",
            "Train Epoch: 2 [50/202 (24%)]\tLoss: 0.661287\n",
            "Train Epoch: 2 [100/202 (49%)]\tLoss: 0.449178\n",
            "Train Epoch: 2 [150/202 (73%)]\tLoss: 0.656151\n",
            "Train Epoch: 2 [80/202 (98%)]\tLoss: 0.316702\n",
            "\n",
            "Test set: Average loss: 0.6605, Accuracy: 40/67 (60%)\n",
            "\n",
            "Train Epoch: 3 [0/202 (0%)]\tLoss: 0.149667\n",
            "Train Epoch: 3 [50/202 (24%)]\tLoss: 0.583143\n",
            "Train Epoch: 3 [100/202 (49%)]\tLoss: 0.713685\n",
            "Train Epoch: 3 [150/202 (73%)]\tLoss: 0.696687\n",
            "Train Epoch: 3 [80/202 (98%)]\tLoss: 0.156514\n",
            "\n",
            "Test set: Average loss: 0.6518, Accuracy: 40/67 (60%)\n",
            "\n",
            "Train Epoch: 4 [0/202 (0%)]\tLoss: 0.831799\n",
            "Train Epoch: 4 [50/202 (24%)]\tLoss: 0.619585\n",
            "Train Epoch: 4 [100/202 (49%)]\tLoss: 0.563846\n",
            "Train Epoch: 4 [150/202 (73%)]\tLoss: 0.362992\n",
            "Train Epoch: 4 [80/202 (98%)]\tLoss: 0.397178\n",
            "\n",
            "Test set: Average loss: 0.6814, Accuracy: 35/67 (52%)\n",
            "\n",
            "Train Epoch: 5 [0/202 (0%)]\tLoss: 0.619475\n",
            "Train Epoch: 5 [50/202 (24%)]\tLoss: 0.699330\n",
            "Train Epoch: 5 [100/202 (49%)]\tLoss: 0.612395\n",
            "Train Epoch: 5 [150/202 (73%)]\tLoss: 0.644746\n",
            "Train Epoch: 5 [80/202 (98%)]\tLoss: 0.918086\n",
            "\n",
            "Test set: Average loss: 0.7182, Accuracy: 27/67 (40%)\n",
            "\n",
            "Train Epoch: 6 [0/202 (0%)]\tLoss: 0.747503\n",
            "Train Epoch: 6 [50/202 (24%)]\tLoss: 0.258326\n",
            "Train Epoch: 6 [100/202 (49%)]\tLoss: 0.583893\n",
            "Train Epoch: 6 [150/202 (73%)]\tLoss: 0.237203\n",
            "Train Epoch: 6 [80/202 (98%)]\tLoss: 0.330197\n",
            "\n",
            "Test set: Average loss: 0.6689, Accuracy: 34/67 (51%)\n",
            "\n",
            "Train Epoch: 7 [0/202 (0%)]\tLoss: 0.730302\n",
            "Train Epoch: 7 [50/202 (24%)]\tLoss: 0.741562\n",
            "Train Epoch: 7 [100/202 (49%)]\tLoss: 0.624736\n",
            "Train Epoch: 7 [150/202 (73%)]\tLoss: 0.324407\n",
            "Train Epoch: 7 [80/202 (98%)]\tLoss: 0.811347\n",
            "\n",
            "Test set: Average loss: 0.6219, Accuracy: 43/67 (64%)\n",
            "\n",
            "Train Epoch: 8 [0/202 (0%)]\tLoss: 0.827353\n",
            "Train Epoch: 8 [50/202 (24%)]\tLoss: 0.516962\n",
            "Train Epoch: 8 [100/202 (49%)]\tLoss: 0.476863\n",
            "Train Epoch: 8 [150/202 (73%)]\tLoss: 0.457278\n",
            "Train Epoch: 8 [80/202 (98%)]\tLoss: 0.701986\n",
            "\n",
            "Test set: Average loss: 0.5896, Accuracy: 52/67 (78%)\n",
            "\n",
            "Train Epoch: 9 [0/202 (0%)]\tLoss: 0.529454\n",
            "Train Epoch: 9 [50/202 (24%)]\tLoss: 0.243139\n",
            "Train Epoch: 9 [100/202 (49%)]\tLoss: 0.303626\n",
            "Train Epoch: 9 [150/202 (73%)]\tLoss: 0.483913\n",
            "Train Epoch: 9 [80/202 (98%)]\tLoss: 0.210061\n",
            "\n",
            "Test set: Average loss: 0.5889, Accuracy: 52/67 (78%)\n",
            "\n",
            "Train Epoch: 10 [0/202 (0%)]\tLoss: 0.313128\n",
            "Train Epoch: 10 [50/202 (24%)]\tLoss: 1.108341\n",
            "Train Epoch: 10 [100/202 (49%)]\tLoss: 0.602423\n",
            "Train Epoch: 10 [150/202 (73%)]\tLoss: 0.511271\n",
            "Train Epoch: 10 [80/202 (98%)]\tLoss: 0.220445\n",
            "\n",
            "Test set: Average loss: 0.5728, Accuracy: 55/67 (82%)\n",
            "\n",
            "Train Epoch: 11 [0/202 (0%)]\tLoss: 0.796503\n",
            "Train Epoch: 11 [50/202 (24%)]\tLoss: 0.579732\n",
            "Train Epoch: 11 [100/202 (49%)]\tLoss: 0.763593\n",
            "Train Epoch: 11 [150/202 (73%)]\tLoss: 0.277364\n",
            "Train Epoch: 11 [80/202 (98%)]\tLoss: 0.439532\n",
            "\n",
            "Test set: Average loss: 0.5880, Accuracy: 51/67 (76%)\n",
            "\n",
            "Train Epoch: 12 [0/202 (0%)]\tLoss: 0.604735\n",
            "Train Epoch: 12 [50/202 (24%)]\tLoss: 0.244574\n",
            "Train Epoch: 12 [100/202 (49%)]\tLoss: 0.552915\n",
            "Train Epoch: 12 [150/202 (73%)]\tLoss: 0.158755\n",
            "Train Epoch: 12 [80/202 (98%)]\tLoss: 0.228304\n",
            "\n",
            "Test set: Average loss: 0.5764, Accuracy: 56/67 (84%)\n",
            "\n",
            "Train Epoch: 13 [0/202 (0%)]\tLoss: 0.514968\n",
            "Train Epoch: 13 [50/202 (24%)]\tLoss: 1.343162\n",
            "Train Epoch: 13 [100/202 (49%)]\tLoss: 0.339197\n",
            "Train Epoch: 13 [150/202 (73%)]\tLoss: 0.423865\n",
            "Train Epoch: 13 [80/202 (98%)]\tLoss: 0.199580\n",
            "\n",
            "Test set: Average loss: 0.5881, Accuracy: 52/67 (78%)\n",
            "\n",
            "Train Epoch: 14 [0/202 (0%)]\tLoss: 0.346235\n",
            "Train Epoch: 14 [50/202 (24%)]\tLoss: 0.278796\n",
            "Train Epoch: 14 [100/202 (49%)]\tLoss: 0.244535\n",
            "Train Epoch: 14 [150/202 (73%)]\tLoss: 0.237401\n",
            "Train Epoch: 14 [80/202 (98%)]\tLoss: 0.338583\n",
            "\n",
            "Test set: Average loss: 0.5882, Accuracy: 52/67 (78%)\n",
            "\n",
            "Train Epoch: 15 [0/202 (0%)]\tLoss: 0.253678\n",
            "Train Epoch: 15 [50/202 (24%)]\tLoss: 0.371989\n",
            "Train Epoch: 15 [100/202 (49%)]\tLoss: 0.421281\n",
            "Train Epoch: 15 [150/202 (73%)]\tLoss: 0.915145\n",
            "Train Epoch: 15 [80/202 (98%)]\tLoss: 0.996934\n",
            "\n",
            "Test set: Average loss: 0.5935, Accuracy: 52/67 (78%)\n",
            "\n",
            "Train Epoch: 16 [0/202 (0%)]\tLoss: 0.708608\n",
            "Train Epoch: 16 [50/202 (24%)]\tLoss: 0.639116\n",
            "Train Epoch: 16 [100/202 (49%)]\tLoss: 0.289057\n",
            "Train Epoch: 16 [150/202 (73%)]\tLoss: 0.670844\n",
            "Train Epoch: 16 [80/202 (98%)]\tLoss: 0.451184\n",
            "\n",
            "Test set: Average loss: 0.5930, Accuracy: 52/67 (78%)\n",
            "\n",
            "Train Epoch: 17 [0/202 (0%)]\tLoss: 0.674168\n",
            "Train Epoch: 17 [50/202 (24%)]\tLoss: 0.350671\n",
            "Train Epoch: 17 [100/202 (49%)]\tLoss: 0.277753\n",
            "Train Epoch: 17 [150/202 (73%)]\tLoss: 0.232001\n",
            "Train Epoch: 17 [80/202 (98%)]\tLoss: 0.333164\n",
            "\n",
            "Test set: Average loss: 0.5903, Accuracy: 51/67 (76%)\n",
            "\n",
            "Train Epoch: 18 [0/202 (0%)]\tLoss: 0.494982\n",
            "Train Epoch: 18 [50/202 (24%)]\tLoss: 0.739197\n",
            "Train Epoch: 18 [100/202 (49%)]\tLoss: 0.500803\n",
            "Train Epoch: 18 [150/202 (73%)]\tLoss: 0.199933\n",
            "Train Epoch: 18 [80/202 (98%)]\tLoss: 0.354485\n",
            "\n",
            "Test set: Average loss: 0.5905, Accuracy: 51/67 (76%)\n",
            "\n",
            "Train Epoch: 19 [0/202 (0%)]\tLoss: 0.277644\n",
            "Train Epoch: 19 [50/202 (24%)]\tLoss: 0.236047\n",
            "Train Epoch: 19 [100/202 (49%)]\tLoss: 0.599479\n",
            "Train Epoch: 19 [150/202 (73%)]\tLoss: 0.388035\n",
            "Train Epoch: 19 [80/202 (98%)]\tLoss: 0.133692\n",
            "\n",
            "Test set: Average loss: 0.5901, Accuracy: 51/67 (76%)\n",
            "\n",
            "Train Epoch: 20 [0/202 (0%)]\tLoss: 0.095336\n",
            "Train Epoch: 20 [50/202 (24%)]\tLoss: 0.212184\n",
            "Train Epoch: 20 [100/202 (49%)]\tLoss: 0.309750\n",
            "Train Epoch: 20 [150/202 (73%)]\tLoss: 0.576902\n",
            "Train Epoch: 20 [80/202 (98%)]\tLoss: 0.483475\n",
            "\n",
            "Test set: Average loss: 0.5901, Accuracy: 51/67 (76%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5tvuSF19qWCT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}